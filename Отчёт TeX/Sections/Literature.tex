\section{Литературный обзор}

С целью поиска информации о локальном координационном числе (что в случае блужданий может также быть названо числом соседей узла), был проведён обзор литературы, возможно имеющей отношение к рассматриваемым в рамках проекта моделей.

\subsection{Livne, Meirovich: Polymers Adsorbed on a surface}

\subsubsection{Особенности модели блуждания}

В работе \cite{LivneSAW1988} исследуется поведение адсорбирующего случайного блуждания без самопересечений на кубической решётке со следующими особенностями симуляции

\begin{itemize}
    \item Случайное блуждание длины N+1  строится пошагово (N+1 мономеров в цепочке или N шагов), из начала координат (x=0, y=0, z=0) с ограничением на верхнее полупространство (то есть, z >= 0 и плоскость z=0 имеет открытые граничные условия).
    \item Энергия конформации считается как число мономеров, лежащих на поверхности (у которых $z_{i} = 0$), умноженное на константу взаимодействия полимера и поверхности $\epsilon$
    \item Вероятность i-й конформации считается последовательно: вводится новая статсумма, суммирующая для заданного направления текущей недостроенной цепочки всевозможные хвосты остаточной длины (10)\cite{LivneSAW1988}. 
\end{itemize}

\subsubsection{Подробнее о статсумме и методе Сканирования }

В данном подразделе вольным образом объясняется действие статсуммы, созданное методом сканированния. Так как при симуляции строится новое блуждание "c нуля", требуется оценка вероятности как каждого шага (точнее, направления $v_{k}$) так и всего блуждания.

Поэтому для k-го шага вероятность рассчитывается следующим образом:

\begin{enumerate}
    \item Считается статсумма куска будущего блуждания из b ($<= N - k + 1$) шагов, начинающая с направления v на высоте $z_{k-1}$:
    
    \begin{equation}
        Z_{k}(v, b, z_{k-1}, v_{k-1}) = \sum_{j}\exp{(-\epsilon m_{j}(0)/k_{b}T)}
        \label{Z_Lenvi}
    \end{equation}
     
    \item Затем проводится расчёт вероятности выбрать направление v из всех возможных на k-м шаге:
    
    \begin{equation}
        p_{k}(v|b,z_{k-1},v_{k-1}) = Z_{k}(v, b, z_{k-1}, v_{k-1}) / \sum_{v} Z_{k}(v, b, z_{k-1}, v_{k-1})
        \label{p_k_Lenvi}
    \end{equation}
    
    \item Итоговой вероятностью всего построения будет произведение всех вероятностей каждого шага по выбранным направлениям:
    
    \begin{equation}
        P_i(b) = \prod_{k=1}^{N} p_{k}(v_{k}|b,z_{k-1},v_{k-1})
    \end{equation}
\end{enumerate}

\subsubsection{Результаты работы}

Основными итогами работы являлось подтверждение эффективности метода "сканирования" для работы с длинными цепочками в модели адсорбирующего блуждания, определено критическое шкалирование перпердикулярного радиуса инерции (радиуса инерции проекции блуждания на ось z), а также профиля мономерной концентрации $p(z)$ (средняя доля узлов конформации длины N+1 на фиксированной высоте z от поверхности).

Информации о локальном координационном числе в статье найдено не было.

\newpage

\subsection{Madras, Sokal: The Pivot Algorithm}

Работа \cite{madras1988pivot} повествует о работе и эффективности алгоритма Пивота в изучении модели случайного блуждания без самопересечений (СБС).

\subsubsection{Основные принципы алгоритма}

Каждый шаг алгоритма проводит следующие действия над уже сгенерированной цепочкой длины N+1:

\begin{itemize}
    \item Случайно выбирается с равномерным распределением для рассматриваемых узлов $p_{k} = 1/N$ k-й узел цепочки ($0 <= k <= N-1$, хотя начальную точку k=0 на практике не используют)
    \item Последующую половину цепочки ($\omega_{k+1}, \omega_{k+2},\dots,\omega_{N}$ заменяют элементов группы симметрии (проще говоря, отражают, поворачивают или проводят комбинацию этих действий)
    \item В случае, если полученная операцией цепочка осталась без самопересечений, шаг принимается - в противном случае, шаг производится заново
\end{itemize}

В статье так же была доказана эргодичность алгоритма, а так же средние вероятности принятия каждого из возможных преобразований.

Для симуляций в качестве стартовой позиции использовалось два варианта: прямые цепочки ''rods'', при которых проволилось некоторое кол-во шагов до достижения термального равновесия системы (в таком состоянии процесс из следующих состояний цепочки становится близким по расспределению к стационарному стохастическому), или же ''димеризованные цепочки'' , состояние которых уже считается равновесным. Второй метод становится крайне времезатратным при большой длине цепочки, поэтому при N>=2400 чаще применялась термолизация прямых цепочек.

Пристальное внимание в статье было обращено к среднему радиусу инерции $S^{2}_{N}$ и квадрату расстояния между концами $\omega^{2}_{N}$, а так же к оценке метрической экспоненты $\upsilon$, характеризующей обе величины в крит. области модели: 

\begin{align*}
    \la \omega^{2}_{N} \ra &\sim N^{2\upsilon} \\
    \la S^{2}_{N} \ra &\sim N^{2\upsilon} 
\end{align*}

В оценке будущей работы было так же отмечено, что алгоритм Пивота не подходит для расчёта связующей $\mu$ и критической $\gamma$ экспонент (связующую константу так же называют \textit{эффективным координационным числом}), так как алгоритм алгоритм работает лишь в случае канонического ансамбля (при фиксированной длине цепочки) и требуется алгоритм, работающий уже в большом каноническом ансамбле (с цепочками изменяемой длины).

В статье не рассматривалось как таковое ''число соседей узлов''.


\subsection{Спицер, Основные принципы случайного блуждания, глава 3}

Данный подраздел посвящён рассмотрению случая двумерного возвратного случайного блуждания - блуждания, движущемся по состояниям $R$ до достижения одного из элементов $A \subset R$. Под $T$ или $T_A$ мы будем подразумевать момент остановки - минимальное число $1<= k <= \infty$, такое что $x_k \in A$, то есть минимальное время достижение процессом {x_i} состояния из пространства A.

\subsubsection{Основные вероятностные функции}

Здесь будут более тщательно описаны используемые в главе функции вероятностей перехода.

$Q_n(x,y)$ определена на $(R-A) \times (R-A),\ \ n >= 0$ и обозначает вероятность попасть на n-м шаге попасть в $y$ (при $x_0 = x$), не попав за это время в A. Логично, что при остановке $T<n$ вероятность достижения на n-м шаге не существует, т.к. проццесс остановлен.

\begin{equation}
 Q_n(x,y) = P_x[x_n=y; T>n]
\end{equation}

Функция $H^{(n)}_A(x,y)$, наоборот, определяет вероятность n-м шаге остановиться в $y \in A$ (то есть, $y$ является первым состоянием из $A$, в которое попал процесс. В данном случае $H_A$ определено на $R \times A$

\begin{equation}
H^{(n)}_A(x,y) = 
	\begin{cases}
		P_x[x_T=y; T=n], \ \ \ x \in R-A \\
		0, \ \ \ x \in A, n>=1 \\
		\delta(x,y), \ \ \ x \in A, n=0
	\end{cases}
\end{equation}

$H_A(x,y)$ является обобщением предыдущей функции по времени, определяя лишь вероятность остановки процесса, начавшегося в $x$, в $y \in A$ и определена там же как и $H^{(n)}_A(x,y)$.

\begin{equation}
H_A(x,y) = 
	\begin{cases}
		P_x[x_T=y; T < \infty], \ \ \ x \in R-A \\
		\delta(x,y), \ \ \ x \in A
	\end{cases}
\end{equation}

Для случая $x \in R-A$ эту функцию можно определить так же как:

\begin{equation}
H_A(x,y) = \sum^{\infty}_{n=0}H^{(n)}_A(x,y)
\end{equation}

Особым случаем является вероятность $\Pi_A(x,y)$, существование которой обусловлено тем фактом, что время остановки должно быть натуральным числом - строго говоря, процесс может начатся в $x \in A$, пройти по ${x_1, x_2,...x_T-1 \in R-A}$ и остановиться в $y \in A$.

\begin{equation}
\Pi_{A}(x,y) = P_x[x_T=y, T < \infty]
\end{equation}

Последняя функция - $g_A(x,y)$, обобщает  по времени $Q_n$:

\begin{equation}
g_A(x,y) = 
	\begin{cases}
		\sum^{\infty}_{n=0}Q_n(x,y), \ \ \ x, y \in R-A \\
		0, otherwise
	\end{cases}
\end{equation}

Из общих понятий нам также понадобится $G(x,y)$ - ожидаемое число попаданий в $y$ при начальной точке $x$:

\begin{equation}
G(x,y) = \sum_{n=0}^{\infty}P_x[x_n=y]
\end{equation}

\subsubsection{Соотношения между функциями}

Перейдём к некоторым предложениям из книги, которые позволят более полно понять природу некоторых функций в зависимости от начального состояния в них. Здесь будет описана лишь их вольная интерпретация, без доказательства.

Для произвольного случайного блуждания:

\begin{equation}
 \sum_{t \in R} P(x,t)H_A(t,y) - H_A(x,y) =  \begin{cases}
							\Pi_A(x,y)-\delta(x,y),\ \ \ x \in A, y\in A \\
							0,\ \ \ x \in R- A, y \in A
						        \end{cases}
	\caption{Предложение 10.1(а)}
\end{equation}

Пункт (а) предложения 10.1 проводит важную связь между $\Pi_A(x,y)$ и $H_A(x,y)$ при разных начальных состояниях: при $x \in R-A$ выражение равно нулю, как так оба слагаемых выражают один и тот же процесс из начального состояния до множества остановки, как со смещением (первое слагаемое), так и без него (правое). Равенство для случая $x \in A$ подтверждает раннюю интерпретацию функции $\Pi_A(x,y)$: шаг из множества остановки (P(x,t)) и затем движение из t до остановки снова в $A$.

\[ 0 \leq g_A(x,y) \leq g_A(y,y) \forall x, y \in R \]

То есть ожидаемое число попаданий из начального состояния x в y в обход A всегда меньше или равно чем ожидаемое число возвращений в начальное состояние. 
Если блуждание является апериодичным, то:

\[ g_A(x,x) < \infty \forall x \in R \]

Для $x \in R-A, y \in A$:

\[ H_A = \sum_{t \in R} g_A(x,t)P(t,y)\]

\[  G(x,y) = \sum_{t \in A} H_A(x,t)G(t,y) \]

\subsubsection{Начало потенциала}

Так как в движении блуждания важнейшую роль играет множество остановки (которое может быть как конечное, так и бесконечное), то основное внимание главы 
уделено распределению конечной точки блуждания $H_A(x,y), x \in R, y \in A$, обсуждение которого начинается с расширения предложения 10.1(а):

\begin{equation}
 \sum_{t \in R} P_{n+1}(x,t)H_A(t,y) = H_A(x,y) + \sum_{t \in A} G_n(x,t)[\Pi_A(t,y)-\delta(t,y)], n \geq 0
	\caption{Предложение 11.1}
\end{equation}

Необходимо заранее подчеркнуть, что это и последующие предложения считаются верными для апериодичных, возвратных, двумерных СБ. Примером такого служит простое
случайное блуждание на плоскости, которое исследовалось под названием Rand_Walk. 
Данное утверждение является первым шагом к исследованию распределения точки блуждания из бесконечно удаленной точки, однако перед этим выражение требует 
некоторых преобразований.

Крайне важным, хотя и очевидным утверждением является следующее предложение:

\begin{equation}
 \sum_{t \in A} \Pi_A(t,y) = \sum_{t \in A} \Pi_A(y,t) = 1, \forall y \in A 
 \caption{предложение 11.2}
\end{equation}

Другими словами, апериодичные возвратные СБ рано или поздно при выходе из множества A попадут в него же. Теперь можно справедливо утверждать, что:

\[ \sum_{t \in A} \Pi_A(t,y) - 1 = \sum_{t \in A} [\Pi_A(t,y) - \delta(t,y)] = 0 \]

Следовательно, мы можем модифицировать 11.1 добавлением любой независимой от t константы, которая будет сокращаться при раскрытии суммы:

\begin{equation}
 \sum_{t \in R} P_{n+1}(x,t)H_A(t,y) = H_A(x,y) + \sum_{t \in A} [G_n(x,t) - G_n(0,0)][\Pi_A(t,y)-\delta(t,y)] = 
	H_A(x,y) - \sum_{t \in A} A_n(x,t)[\Pi_A(t,y)-\delta(t,y)] 
	\caption{Предложение 11.3}
\end{equation}

Именно с этого утверждения возникает задача перехода обоих частей предложения к пределу $n \to \infty$. Опуская доказательства существования пределов, положим
следующие ответы.

\begin{enumerate}
\item $\lim_{n \to \infty} A_n(x,y)$ существует и определен как $A(x,y)$ 
\item $\sum_{t \in R} P_{n+1}(x,t)H_A(t,y)$ существует, не зависит от t и определён как $\mu_A(y)$ 
\end{enumerate}

Пока что промежуточным после последних рассуждений выражением для распределения конечной точки СБ при бесконечном (или неопределенном) числе шагов является:

\begin{equation}
 H_A(x,y) = \mu_A(y) + \sum_{t \in A} A(x,t)[\Pi_A(t,y)-\delta(t,y)]
 \caption{Предложение 11.4}
 \label{eq:H_a_xy}
\end{equation}

Так же будет полезным рассмотреть не только движение из бесконечности до множества A, но и движение вокруг него - то есть, перемещение 
из $x \in A$ в $y \in A$. Очевидно, для этого важно более чётко определить способы использования функции $\Pi_A(x,y)$.

При рассмотрении некоторого конечного множества точек $B \subset R$, функция A(x,y) легко представима в виде матрицы ${A(x,y)}, x,y \in B$, которое называется 
\textit{сужением оператора $A(x,y)$ на $B$}. Такая матрица всегда имеет обратную, если $|B| \geq 2$ (предложение 11.8). Тем самым, мы получаем новый оператора
$K_B(x,y)$, определенный так же на $B \times B$:

\[ \sum_{t \in B} A(x,t) K_B(t,y) = \delta(x,y), x,y \in B \]

Далее исследуемое остановочное множество мы будем обозначать как $B$, так как $A$ занято новой функцией.
Определим так же ещё несколько вспомогательных функций и константу:

\begin{align*} 
K_B(\cdot y) &= \sum_{x \in B} K_B(x,y)
K_B(x \cdot) &= \sum_{y \in B} K_B(x,y)
K_B(\cdot \cdot) &= \sum_{x \in B} \sum_{y \in B} K_B(x,y)
\end{align*}

Все эти инструменты помогут в определении и доказательстве основной теоремы параграфа, в которой, помимо самого предложения 11.4, есть нужная нам модификация.
В случае $x,y \in B$ для \eqref{eq:H_a_xy} получим следующее выражение:

\[ \delta(x,y) = \mu_B(y) + \sum_{t \in B} A(x,t)[\Pi_B(t,y)-\delta(t,y)] \] 

Будет разумно перейти к матричной форме: левая часть будет единичной матрицей, первое слагаемое правой части будет матрицей $M_B$ размера $|B| \times |B|$, 
каждая строка которой - вектор значений \mu_B(y), а второе - результат произведения матрицами сужений оператора A(x,y) и $\Pi - E$ на $B \times B$. Получим:

\[ E = M_B + A \times (\Pi_B - E) \]

Применим оператор $K_B$ слева:

\[ K_B = K_B \times M_B + \Pi_B - E \]

Переход к элементам даст нам знакомые функции:

\[ K_B(x, y) = K_B(x \cdot) \mu_B(y) + (\Pi_B - \delta(x,y))\] 

Операция суммирования по строкам приведёт нас к двум важным пунктам теоремы:

\[ K_B(\cdot y) = K_B(\cdot \cdot) \mu_B(y) \rightarrow \mu_B(y) = \frac{K_B(\cdot y)}{K_B(\cdot \cdot)},\ \ \ K_B(\cdot \cdot) > 0 \]

Второй пункт выводится из ряда противоречий: если $K_B(\cdot \cdot) = 0$, то $K_B(\cdot y) = 0$ и матрица вырожденная и не имеет обратной (то есть, A(x,y) 
не существует). Если K_B(\cdot \cdot) < 0, то $K_B(\cdot y) < 0$, однако из определения K_B: 

\[ \sum_{t \in B} A(x,t) K_B(t,y) = \sum_{t \in B} K_B(x,t) A(t,y) = \delta(x,y) \rightarrow \sum_{t \in B} \sum_{x \in B} K_B(x,t) A(t,y) = 1 > 0 \]

$A(x,y) \geq 0$ из предложения 11.7, поэтому снова противоречие.
Подстановка первого доказанного пункта в ранние выкладки даст нам последний пункт теоремы:

\Pi_B(x,y) - \delta(x,y) = K_B(x,y) - \frac{K_B(x \cdot) K_B(\cdot y)}{K_B(\cdot \cdot)}

В итоге мы увидели, насколько мощным инструментом является функция $A(x,y)$ даже в сужении на $B$: её вычисление позволяет моментально рассчитать распределение 
конечного состояния из бесконечно удалённого, или распределение при возвращении во множество B. Теперь важнейшей задачей является расчёт самой функции $A(x,y)$,
далее известное как ядро потенциала блуждания.

\subsubsection{Основные вероятности в СБ в рамках гармонического анализа}

\subsubsection{Примеры в физике}

\subsubsection{Движение из бесконечности}

\subsubsection{Простое случайное блуждание на плоскости}

